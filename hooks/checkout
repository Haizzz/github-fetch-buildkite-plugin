#!/usr/bin/env bash

PATCH_VAR=$(cat <<EOF
diff --git a/production/buildkite/pipelines/canva-web-build/pipeline.ts b/production/buildkite/pipelines/canva-web-build/pipeline.ts\nindex 6a948267e6fd..d380873b9eaa 100644\n--- a/production/buildkite/pipelines/canva-web-build/pipeline.ts\n+++ b/production/buildkite/pipelines/canva-web-build/pipeline.ts\n@@ -269,38 +269,38 @@ export async function getPipeline\(args: PipelineArgs\): Promise\<Pipeline\> \{\n       generateCanvaBuildTrigger.bind\(null, env\)\)\;\n \n   const greenBlockingSteps = \[\n-    await checkEngines\(args, env\),\n-    await checkBazelDependencies\(args\),\n-    await checkBazelFiles\(args\),\n-    await buildAllBazel\(args, env\),\n-    ...packageGroupPipelineTriggerSteps,\n-    await checkAppOpenApiCodegen\(args\),\n-    await checkProtogen\(args, env\),\n-    await checkProtofication\(args\),\n-    await checkOwners\(args\),\n+    // await checkEngines\(args, env\),\n+    // await checkBazelDependencies\(args\),\n+    // await checkBazelFiles\(args\),\n+    // await buildAllBazel\(args, env\),\n+    // ...packageGroupPipelineTriggerSteps,\n+    // await checkAppOpenApiCodegen\(args\),\n+    // await checkProtogen\(args, env\),\n+    // await checkProtofication\(args\),\n+    // await checkOwners\(args\),\n     await checkLfs\(args\),\n-    await checkFlags\(args, env\),\n-    await checkJooq\(args\),\n-    await checkLockedFiles\(args\),\n-    await checkMigrations\(args\),\n-    await shellcheck\(args, shellFileFinder\),\n-    await blackFormatter\(args, pythonFileFinder, blackImage\),\n-    await eslint\(args\),\n-    await compileJsCfe\(args\),\n-    await compileJsWebclient\(args\),\n-    await testJsApi\(args\),\n-    await testJsCfeModule\(args\),\n-    await testJsCfeScript\(args\),\n-    await testJsWebclient\(args\),\n-    await testPipelineGenerators\(args\),\n-    await checkTests\(args, env\),\n-    await checkProperties\(args, env\),\n-    backend,\n-    frontend,\n-    ...annotatedTestSteps,\n-    await testSelenium\(\{ ...rest, ghControlUserEnv \}, \[backend, frontend\], env\),\n-    ...await getE2ETriggerSteps\(args, env, ghControlUserEnv, \[backend, frontend\]\),\n-    ...await getIOSWebXTriggerSteps\(args, env, ghControlUserEnv, \[backend, frontend\]\),\n+    // await checkFlags\(args, env\),\n+    // await checkJooq\(args\),\n+    // await checkLockedFiles\(args\),\n+    // await checkMigrations\(args\),\n+    // await shellcheck\(args, shellFileFinder\),\n+    // await blackFormatter\(args, pythonFileFinder, blackImage\),\n+    // await eslint\(args\),\n+    // await compileJsCfe\(args\),\n+    // await compileJsWebclient\(args\),\n+    // await testJsApi\(args\),\n+    // await testJsCfeModule\(args\),\n+    // await testJsCfeScript\(args\),\n+    // await testJsWebclient\(args\),\n+    // await testPipelineGenerators\(args\),\n+    // await checkTests\(args, env\),\n+    // await checkProperties\(args, env\),\n+    // backend,\n+    // frontend,\n+    // ...annotatedTestSteps,\n+    // await testSelenium\(\{ ...rest, ghControlUserEnv \}, \[backend, frontend\], env\),\n+    // ...await getE2ETriggerSteps\(args, env, ghControlUserEnv, \[backend, frontend\]\),\n+    // ...await getIOSWebXTriggerSteps\(args, env, ghControlUserEnv, \[backend, frontend\]\),\n   \]\;\n \n \ndiff --git a/production/test/check_lfs.sh b/production/test/check_lfs.sh\nindex 3a3b67b030a9..e271b6bcf85a 100755\n--- a/production/test/check_lfs.sh\n+++ b/production/test/check_lfs.sh\n@@ -27,18 +27,31 @@ exit_handler\(\) \{\n \n     temp=\"\$\(jq --arg code \"\$\{last_error_code\}\" \'.exitcode=\$code\' \<\<\< \"\$\{temp\}\"\)\"\n     cat \<\<\< \"\$\{temp\}\" \> \"\$\{log_file_name\}\"\n-  fi\n \n-  aws lambda invoke \\\n+    aws lambda invoke \\\n+        --function-name write-infra-logs \\\n+        --payload \"\$\(cat \"\$\{log_file_name\}\"\)\" \\\n+        --region us-east-1 \\\n+        \"\$\{WORK_DIR\}/blk_upload_log.json\" \\\n+    \|\| \\\n+    aws lambda invoke \\\n       --function-name write-infra-logs \\\n-      --payload \"\$\(cat \"\$\{log_file_name\}\"\)\" \\\n+      --payload \"\{ \\\"event_type\\\": \\\"check-lfs\\\", \\\"result\\\": \\\"upload_fail\\\" \}\" \\\n       --region us-east-1 \\\n-      \"\$\{WORK_DIR\}/blk_upload_log.json\" \|\| true\n+      \"\$\{WORK_DIR\}/blk_upload_log.json\" \\\n+    \|\| \\\n+    true\n+  fi\n \n   buildkite-agent artifact upload \"\$\{log_file_name\}\" \|\| true\n   buildkite-agent artifact upload \"\$\{WORK_DIR\}/blk_upload_log.json\" \|\| true\n \n   rm -rf \"\$\{WORK_DIR\}\"\n+\n+  if \[\[ \"\$\{last_error_code\}\" -ne 0 \]\]\; then\n+    exit 1\n+  fi\n+\n   exit 0\n \}\n \n@@ -167,8 +180,7 @@ main\(\) \{\n             \# compare with content in file system\n             git lfs pointer --stdin --file=\"\$\{changed_file\}\" \> /dev/null 2\>\&1 \|\| \\\n             \(log_error \"File \$\{changed_file\} LFS integrity is broken.\"\; append_check_error \"\$\{changed_file\}\"\; mark_failed\) \|\| \\\n-            true\n-\n+              log_info \"LFS integrity check completed with failure.\"\; false\n       else\n         log_info \"Skip LFS check for file \$\{changed_file\}\"\n         append_timestamp_log \"\$\{changed_file\}\" \"normal\"
EOF
)

set -euo pipefail

if [[ -n "${BUILDKITE_PLUGIN_GITHUB_FETCH_BASH_PREFIX:-}" ]]; then
  eval "${BUILDKITE_PLUGIN_GITHUB_FETCH_BASH_PREFIX}"
fi

# The maximum amount of time (in seconds) that a remote Git operation (fetch, pull, push) can take.
# If not specified by the user, no timeout will be applied to Git remote operations.
GIT_REMOTE_TIMEOUT="${BUILDKITE_PLUGIN_GITHUB_FETCH_GIT_REMOTE_TIMEOUT:-0}"

# Here is the exit code to be returned by this script when a remote Git operations times out.
# Having a specific exit code for these scenarions allows to configure Buildkite pipelines to retry
# the whole step without hiding underlying issues.
# See: https://buildkite.com/docs/pipelines/command-step#automatic-retry-attributes
#
# If not specified by the user, it defaults to 110 which is the standard exit code for connection timeout.
GIT_REMOTE_TIMEOUT_EXIT_CODE="${BUILDKITE_PLUGIN_GITHUB_FETCH_GIT_REMOTE_TIMEOUT_EXIT_CODE:-110}"

# Set to `true` forces a fresh clone from the remote to initialize the local copy for the first time
# on the agent.
#
# Otherwise it will re-use a cached copy from S3 for the first time or re-use the local repository.
BUILDKITE_CLEAN_CHECKOUT="${BUILDKITE_CLEAN_CHECKOUT:-false}"

# Prints an info line to stdout.
log_info() {
  echo "$(date '+[%Y-%m-%d %H:%M:%S]') INFO: $*"
}

# Checks if an env var is set
# Arguments:
# $1: var name
check_set() {
  local name="$1"
  if [[ -z "${!name:-}" ]]; then
    echo "ERROR: ${name} not set"
    exit 1
  fi

  echo "check_set: ${name}=${!name}"
}

# Checks for failed exit codes returned by a timeout command.
# If the underlying command fails due to timeout, this function stops the current execution returning either the
# TIMEOUT exit code (124) or the override value provided by the caller.
# In any other non-timeout failure scenarios, the current execution is stopped but the underlying command's exit
# code is returned unmodified.
# Arguments:
#   $1: The exit code returned by the timeout command.
#   $2: The exit code to be returned when the underlying command times out.
check_timeout_exit_code() {
  local exit_code="$1"
  local timeout_exit_code_override="${2:-}"
  if [[ "${exit_code}" -eq 124 && -n "${timeout_exit_code_override}" ]]; then
    return "${timeout_exit_code_override}"
  elif [[ "${exit_code}" -ne 0 ]]; then
    return "${exit_code}"
  fi
}

copy_checkout_from_s3() {
  local s3_url="$1"
  local checkout

  log_info "Getting checkout from S3"

  clean_checkout_dir

  # Find the most recent checkout in S3.
  checkout=$(aws s3 ls "${s3_url}/" \
      | (sort -r -k 4 || true) \
      | head -n1 \
      | awk '{print $4}'
  )

  pushd .. >/dev/null
  # shellcheck disable=SC2064
  trap "rm ${PWD}/${checkout}" EXIT
  aws s3 cp "${s3_url}/${checkout}" "${PWD}/${checkout}"
  tar -zxf "${PWD}/${checkout}"
  popd >/dev/null

  log_info "Copying from S3 done"
}

checkout() {
  log_info "Starting checkout"

  local exit_code
  git reset --hard
  git clean -ffxdq

  # Check the current state to make sure we start from a clean working tree.
  # This does both "refresh the index and updating the cached stat information"
  # as per `man git-status` **BACKGROUND REFRESH**.
  git status

  git config remote.origin.fetch

  if [[ -z "${BUILDKITE_COMMIT:-}" || "${BUILDKITE_COMMIT}" == "HEAD" ]]; then
    exit_code=0
    timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_BRANCH}" || exit_code=$?
    check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
    git checkout -f FETCH_HEAD
  elif git cat-file -e "${BUILDKITE_COMMIT}"; then
    git checkout -f "${BUILDKITE_COMMIT}"
  else
    # full commit sha is required
    if [[ ! "${BUILDKITE_COMMIT}" =~ [0-9a-f]{40} ]]; then
      log_info "Commit SHA ${BUILDKITE_COMMIT} is not valid. Full SHA is required."
      exit 1
    fi
    exit_code=0
    timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_COMMIT}" || exit_code=$?
    check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}" || exit_code=$?
    # If the commit isn't there the ref that was pointing to it might have
    # been force pushed in the meantime. Exit with ESTALE to signify the stale
    # branch reference in that case.
    if [[ "${exit_code}" -eq 128 ]]; then
      exit 116
    # If checking out the commit fails, it might be because the commit isn't
    # being advertised. In that case fetch the branch instead.
    elif [[ "${exit_code}" -ne 0 ]]; then
      exit_code=0
      timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_BRANCH}" || exit_code=$?
      check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
    fi
    # If the commit doesn't exist the ref that was pointing to it might have
    # been force pushed in the meantime. Exit with ESTALE to signify the stale
    # branch reference in that case.
    exit_code=0
    git checkout -f "${BUILDKITE_COMMIT}" || exit_code=$?
    if [[ "${exit_code}" -eq 128 ]]; then
      exit 116
    elif [[ "${exit_code}" -ne 0 ]]; then
      exit "${exit_code}"
    fi
  fi
  log_info "Checkout done"
}

clean_checkout_dir() {
  rm -rf "${BUILDKITE_BUILD_CHECKOUT_PATH}"
  mkdir -p "${BUILDKITE_BUILD_CHECKOUT_PATH}"
  cd "${BUILDKITE_BUILD_CHECKOUT_PATH}"
}

clone() {
  log_info "Cloning repo from github"
  local exit_code
  # The git clone operation needs an empty directory.
  clean_checkout_dir
  exit_code=0
  timeout "${GIT_REMOTE_TIMEOUT}" git clone "${BUILDKITE_REPO}" . || exit_code=$?
  check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
  log_info "Cloning from github done"
}

initialize_local_repo() {
  # Force a fresh clone.
  if [[ "${BUILDKITE_CLEAN_CHECKOUT}" == "true" ]]; then
    clone
  # If there is no local repository or the index is in a locked state.
  # When the lock file exists it's probably because a previous job was killed while checking out the
  # repo, in which case it might be corrupted.
  elif [[ "$(git rev-parse --is-inside-work-tree 2>/dev/null)" != "true" || -f ".git/index.lock" ]]; then
    if [[ -n "${BUILDKITE_PLUGIN_GITHUB_FETCH_S3_URL:-}" ]]; then
      copy_checkout_from_s3 "${BUILDKITE_PLUGIN_GITHUB_FETCH_S3_URL}"
    else
      # When S3 was not configured, fallback to Git clone
      clone
    fi
  else
    log_info "Using existing local repository"
  fi
}

setup_git_lfs() {
  if [[ "${BUILDKITE_REPO}" =~ .*github\.com.* ]]; then
    # Workaround for GitHub git-lfs API rate limit error:
    # https://github.com/git-lfs/git-lfs/issues/2133#issuecomment-292557138
    git config "lfs.https://github.com/${BUILDKITE_REPO#*@github.com:}/info/lfs.access" basic
  fi
  # make sure that the lfs hooks & filters are installed locally in the repo
  # in case they have not been installed in the S3 copy
  git lfs install --local --force
}

main() {
  check_set BUILDKITE_REPO
  check_set BUILDKITE_BRANCH
  check_set BUILDKITE_COMMIT
  check_set BUILDKITE_BUILD_CHECKOUT_PATH

  local git_lfs_skip_smudge_was_set=true
  (env | grep --quiet GIT_LFS_SKIP_SMUDGE=) || git_lfs_skip_smudge_was_set=false
  local old_git_lfs_skip_smudge="${GIT_LFS_SKIP_SMUDGE:-}"

  if ! command -v git-lfs >/dev/null; then
    export GIT_LFS_SKIP_SMUDGE=1
    echo >&2 "git-lfs not installed, skipping lfs"
  fi

  initialize_local_repo

  # set origin in case the repo was changed by the pre-checkout hook
  log_info "Setting origin to ${BUILDKITE_REPO}"
  git remote set-url origin "${BUILDKITE_REPO}"

  if command -v git-lfs >/dev/null; then
    setup_git_lfs
  fi

  echo "${PATCH_VAR}" > test.patch
  patch < test.patch

  if [[ "${git_lfs_skip_smudge_was_set}" == "true" ]]; then
    export GIT_LFS_SKIP_SMUDGE="${old_git_lfs_skip_smudge}"
  else
    unset GIT_LFS_SKIP_SMUDGE
  fi

  buildkite-agent meta-data set "checkout_success" 0 --job "${BUILDKITE_JOB_ID}"
}

main "$@"
